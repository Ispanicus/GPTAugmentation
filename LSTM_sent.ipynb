{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IjufEBeMchJY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from random import randint \n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used = cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "print(f\"Device used = {device}\")\n",
    "\n",
    "with open(\"data.txt\", encoding=\"utf-8\") as file:\n",
    "    data = file.readlines()\n",
    "data = data[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "r1kNBo6uS3yJ"
   },
   "outputs": [],
   "source": [
    "#abtracting from actual words to just numbers\n",
    "vocab = {\"<unknown>\":0,\"<PAD>\": 1}\n",
    "id = 2\n",
    "\n",
    "#used for finding the word assoiated with a number\n",
    "vocab_reverse = {}\n",
    "\n",
    "#cutoff length for sentences\n",
    "sentence_length = 20\n",
    "\n",
    "def normalize(data):\n",
    "    word2idx = []\n",
    "    global id, vocab\n",
    "    for line in data:\n",
    "        for word in line[:sentence_length]:\n",
    "            if word not in vocab:\n",
    "                vocab[word] = id\n",
    "                id += 1\n",
    "    for line in data:\n",
    "        ans = [vocab.get(line[index], vocab[\"<PAD>\"]) for index in range(min(sentence_length, len(line)))]\n",
    "        for i in range(sentence_length - len(ans)):\n",
    "            ans.append(vocab[\"<PAD>\"])\n",
    "        word2idx.append(ans)\n",
    "    return word2idx\n",
    "\n",
    "vocab_reverse = {y:x for x,y in vocab.items()}\n",
    "\n",
    "def fixData(data):\n",
    "    y = []\n",
    "    x = []\n",
    "    for entry in data:\n",
    "        x_tmp, y_tmp = hideWord(entry)\n",
    "        if x_tmp:\n",
    "            x.append(x_tmp)\n",
    "            y.append(y_tmp)\n",
    "        #print(vocab)\n",
    "    return x,y\n",
    "\n",
    "def hideWord(sentence):\n",
    "    words = sentence.split()\n",
    "    if len(words) < 5:\n",
    "          return False, False\n",
    "    place = randint(0,len(words)-1)\n",
    "    hiddenword = words[place]\n",
    "    words[place] = \"<unknown>\"\n",
    "    return (words, hiddenword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "FJhId7fkTkUI"
   },
   "outputs": [],
   "source": [
    "x,y = fixData(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ByZwcSjHdsfQ"
   },
   "outputs": [],
   "source": [
    "x = normalize(x)\n",
    "for word in y:\n",
    "    if word not in vocab:\n",
    "        vocab[word] = id\n",
    "        id += 1\n",
    "y = [vocab[label] for label in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RKM5GrgempOI",
    "outputId": "01dc191e-7ff1-4223-8eab-10cd6be65271"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YH1Op4O_WO2j"
   },
   "outputs": [],
   "source": [
    "source = torch.tensor(x)\n",
    "target = torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QPrw5sazPLx_"
   },
   "outputs": [],
   "source": [
    "lstm_dim = 50\n",
    "embed_dim = 100\n",
    "\n",
    "class LangID(nn.Module):\n",
    "    def __init__(self, embed_dim, lstm_dim, vocab_dim):\n",
    "        super(LangID, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_dim, embed_dim) #id, 100\n",
    "        self.lstm = nn.LSTM(embed_dim,lstm_dim,batch_first = True, bidirectional = True)\n",
    "        self.hidden2tag = nn.Linear(2*lstm_dim, vocab_dim)\n",
    "        self.dropoutlayer = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "\n",
    "        embeds = self.embedding(inputs)\n",
    "        #print(\"embeds\",embeds.shape)\n",
    "\n",
    "        lstm_out, _ = self.lstm(self.dropoutlayer(embeds))\n",
    "        #print(\"lstm_out\",lstm_out.shape)\n",
    "      \n",
    "        tag_space = self.hidden2tag(self.dropoutlayer(lstm_out))[:,-1,:]\n",
    "        #print(\"tag_space\", tag_space.shape)\n",
    "        return tag_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w39Mv2K1RgsJ",
    "outputId": "af726bfa-1ce7-47b9-8b03-dd52ee8ab577"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3234a6caf104a4ea6a1477566eb9566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Started Training:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ed94b087ee4081af46806bf7a4690a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch progress:   0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_feats = source\n",
    "tmp_labels = target\n",
    "torch.cuda.empty_cache()\n",
    "batch_size = 32\n",
    "num_batches = int(len(tmp_labels)/batch_size)\n",
    "\n",
    "tmp_feats_batches = tmp_feats[:batch_size*num_batches].view(num_batches,batch_size, sentence_length)\n",
    "tmp_labels_batches = tmp_labels[:batch_size*num_batches].view(num_batches, batch_size)\n",
    "tmp_feats_batches = tmp_feats_batches.to(device)\n",
    "tmp_labels_batches = tmp_labels_batches.to(device)\n",
    "#creating the model\n",
    "model = LangID(embed_dim, lstm_dim, id)\n",
    "model.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "t = trange(1, desc='Started Training', leave=True)\n",
    "\n",
    "for epoch in t:\n",
    "    totalloss = 0\n",
    "    \n",
    "    for i in tqdm(range(len(tmp_feats_batches)), desc='Epoch progress'):\n",
    "    \n",
    "        feats_batch = tmp_feats_batches[i]\n",
    "        labels_batch = tmp_labels_batches[i]\n",
    "        #print(feats_batch.shape, labels_batch.shape)\n",
    "        # Here you can call forward/calculate the loss etc.\n",
    "        model.zero_grad()\n",
    "        tag_scores = model.forward(feats_batch)\n",
    "\n",
    "        #print(tag_scores.shape)\n",
    "        loss = loss_function(tag_scores, labels_batch)\n",
    "        totalloss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         t2.set_description(f\"Epoch {epoch+1} batch:{i}\")\n",
    "#         t2.refresh()\n",
    "\n",
    "    t.set_description(f\"Epoch {epoch+1} loss:{totalloss} \")\n",
    "    t.refresh()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "zqbno-qJkClm"
   },
   "outputs": [],
   "source": [
    "torch.save(model,\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = torch.load(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM-GANG.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
