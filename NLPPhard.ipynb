{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "second-equality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60783"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def load_data(path):\n",
    "    data = []\n",
    "    cols = {'verified':0,'reviewTime':1,'reviewerID':2,'asin':3,\"reviewText\":4,\"summary\":5,\"unixReviewTime\":6,\"sentiment\":7,\"id\":8}\n",
    "    for line in open(path):\n",
    "        review_data = json.loads(line)\n",
    "        tmp = [None]*len(cols)\n",
    "        for key in review_data:\n",
    "            if key in cols:\n",
    "                if key == \"sentiment\":\n",
    "                    tmp[cols[key]] = 1 if review_data[key] == \"positive\" else 0\n",
    "                else:\n",
    "                    tmp[cols[key]] = str(review_data[key])\n",
    "        data.append(tmp)\n",
    "    X = pd.DataFrame(data, columns=cols)\n",
    "    # set empty reviews to '' (instead of None)\n",
    "    X.loc[X['reviewText'].isna(), 'reviewText'] = ''\n",
    "    X.loc[X['summary'].isna(), 'summary'] = ''\n",
    "    y = X['sentiment']\n",
    "    X.drop(columns='sentiment', inplace=True)\n",
    "    return X, y\n",
    "\n",
    "df, target = load_data('Data/music_reviews_train.json')\n",
    "df_dev, y_dev = load_data('Data/music_reviews_dev.json')\n",
    "df_test, y_test = load_data('Data/music_reviews_test_masked.json')\n",
    "df_hard, y_hard = load_data('Data/phase_2_masked.json')\n",
    "sum(target)/len(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-phoenix",
   "metadata": {},
   "source": [
    "## Reason why we don't have max document frequency\n",
    "\n",
    "Words that appear in more than 5% of the reviews: ['album', 'best', 'better', 'buy', 'cd', 'don', 'good', 'great', 'heard', 'just', 'know', 'like', 'listen', 'love', 'music', 'new', 'really', 'song', 'songs', 'sound', 'time', 'version', 'voice', 'way']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alone-murder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 100000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = (df[\"reviewText\"]+\" \"+df[\"summary\"]).to_list()\n",
    "len(X_train), len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "skilled-insight",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c27f743ed223>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m'clf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m ])\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Users\\Christoffer\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Christoffer\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1404\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1405\u001b[0m             \u001b[0mprefer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'processes'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1406\u001b[1;33m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m   1407\u001b[0m                                \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1408\u001b[0m             path_func(X, y, pos_class=class_, Cs=[C_],\n",
      "\u001b[1;32mD:\\Users\\Christoffer\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Christoffer\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Christoffer\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Christoffer\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Christoffer\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Christoffer\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Christoffer\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Christoffer\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Users\\Christoffer\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[0;32m    756\u001b[0m             iprint = [-1, 50, 1, 100, 101][\n\u001b[0;32m    757\u001b[0m                 np.searchsorted(np.array([0, 1, 2, 3]), verbose)]\n\u001b[1;32m--> 758\u001b[1;33m             opt_res = optimize.minimize(\n\u001b[0m\u001b[0;32m    759\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"L-BFGS-B\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Christoffer\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    617\u001b[0m                                   **options)\n\u001b[0;32m    618\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[0;32m    620\u001b[0m                                 callback=callback, **options)\n\u001b[0;32m    621\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Christoffer\\anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Christoffer\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Christoffer\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Christoffer\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Christoffer\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Christoffer\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Christoffer\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Christoffer\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_logistic_loss_and_grad\u001b[1;34m(w, X, y, alpha, sample_weight)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[0mz0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m     \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;31m# Case where we fit the intercept.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Christoffer\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Christoffer\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class OnehotTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def convert(self, sentence):# [[w1, w2, w3], [w1, w2, w3]]\n",
    "        output = [0]*len(self.vocab)\n",
    "        for word in sentence.split():\n",
    "            word = word.lower()\n",
    "            if word in self.vocab:\n",
    "                output[self.vocab[word]] = 1\n",
    "        return output\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        vectorizer = TfidfVectorizer(min_df = 25)\n",
    "        vectorizer.fit(X)\n",
    "        self.vocab = vectorizer.vocabulary_\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_ = [self.convert(row) for row in X]\n",
    "        return X_\n",
    "\n",
    "    \n",
    "pipe = Pipeline([\n",
    "    ('onehot', OnehotTransformer()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "pipe.fit(X_train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "basic-frederick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9207"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score((df_dev[\"reviewText\"]+\" \"+df_dev[\"summary\"]).to_list(), y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fatal-howard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Redman has been my cherished rapper since he guest featured on EPMD\\'s \"Hardcore\" on their sophomore album \"Business As Usual\". \"Muddy Waters\" is still one of my cherished albums of all time. I\\'m extremely disconcerted with \"Reggie\". If Red was arduous to figure out a way to alienate his loyal target audience he accomplished it with this album. Lyrically he is still \"Red\" but those tracks are straight junk. I would expect one of these new \"Here Today, Gone Tomorrow\" artists (and there are many)to use tracks like this not a Hip Hop legend. The one thing I\\'ve always loved about Redman(his loyal followers would probably agree with me on this) is that he was always in his own lane-a lane he created. His sound was unique to him and there was no one else like him. He has gotten away from the sound and style that made him Redman. He is still one of my cherished rappers I just hope he comes correct on his next project. Out like a light!',\n",
       " 'My dentist recommended this as a relaxation technique for dental visits. They give me an ipod with headphones, play this on it and it relieves some of the stress of dental treatment, which I dislike intensely.\\nIt worked so well that I bought my own copy to try at home. I fall asleep after a couple of minutes and stay asleep. Instead of tossing and turning, I hardly move at all. Highly recommend. Out like a light!')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_hard[\"reviewText\"]+\" \"+df_dev[\"summary\"]).to_list()[0], (df_dev[\"reviewText\"]+\" \"+df_dev[\"summary\"]).to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "durable-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = (df_hard[\"reviewText\"]+\" \"+df_hard[\"summary\"]).to_list()\n",
    "predictions = pipe.predict(X_test)\n",
    "\n",
    "with open('submission.csv', mode='w',newline='') as file:\n",
    "    writer = csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    writer.writerow(['id', 'prediction'])\n",
    "    for idx, pred in enumerate(predictions):\n",
    "        writer.writerow([str(idx),str(pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "voluntary-breakfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(pipe, open(\"model.obj\", 'wb'), protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "expected-runner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38559888 0.61440112]\n"
     ]
    }
   ],
   "source": [
    "with open('Data/tests_n500', encoding='UTF-8') as f:\n",
    "    X_test = f.readlines()\n",
    "\n",
    "predictions = pipe.predict(X_test)\n",
    "predictions_percentage = pipe.predict_proba(X_test)\n",
    "print(predictions_percentage[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "essential-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/checklist.pred', mode='w') as file:\n",
    "    for pred, perc in zip(predictions, predictions_percentage):\n",
    "        neg, pos = perc\n",
    "        if pred == 1:\n",
    "            pred += 1\n",
    "        \n",
    "        file.write(f'{pred} {neg} 0.0 {pos}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "peaceful-fetish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, array([0.38559888, 0.61440112]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0], predictions_percentage[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "passive-interstate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "single positive words\n",
      "Test cases:      34\n",
      "Fails (rate):    1 (2.9%)\n",
      "\n",
      "Example fails:\n",
      "0.7 0.0 0.3 admired\n",
      "----\n",
      "\n",
      "\n",
      "single negative words\n",
      "Test cases:      35\n",
      "Fails (rate):    13 (37.1%)\n",
      "\n",
      "Example fails:\n",
      "0.4 0.0 0.6 dreaded\n",
      "----\n",
      "0.2 0.0 0.8 rough\n",
      "----\n",
      "0.4 0.0 0.6 abhorred\n",
      "----\n",
      "\n",
      "\n",
      "single neutral words\n",
      "Test cases:      13\n",
      "Fails (rate):    13 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "0.4 0.0 0.6 saw\n",
      "----\n",
      "0.3 0.0 0.7 private\n",
      "----\n",
      "0.4 0.0 0.6 international\n",
      "----\n",
      "\n",
      "\n",
      "Sentiment-laden words in context\n",
      "Test cases:      8658\n",
      "Test cases run:  500\n",
      "Fails (rate):    170 (34.0%)\n",
      "\n",
      "Example fails:\n",
      "0.4 0.0 0.6 I despise this food.\n",
      "----\n",
      "0.4 0.0 0.6 This food was sad.\n",
      "----\n",
      "0.4 0.0 0.6 I despise this cabin crew.\n",
      "----\n",
      "\n",
      "\n",
      "neutral words in context\n",
      "Test cases:      1716\n",
      "Test cases run:  500\n",
      "Fails (rate):    500 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "0.6 0.0 0.4 This customer service was Indian.\n",
      "----\n",
      "0.4 0.0 0.6 The flight is British.\n",
      "----\n",
      "0.6 0.0 0.4 The company was commercial.\n",
      "----\n",
      "\n",
      "\n",
      "intensifiers\n",
      "Test cases:      2000\n",
      "Test cases run:  500\n",
      "Fails (rate):    104 (20.8%)\n",
      "\n",
      "Example fails:\n",
      "0.2 0.0 0.8 This was a beautiful flight.\n",
      "0.5 0.0 0.5 This was an utterly beautiful flight.\n",
      "\n",
      "----\n",
      "0.4 0.0 0.6 I abhorred this food.\n",
      "0.5 0.0 0.5 I honestly abhorred this food.\n",
      "\n",
      "----\n",
      "0.6 0.0 0.4 We dislike that service.\n",
      "0.3 0.0 0.7 We truly dislike that service.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "reducers\n",
      "Test cases:      2000\n",
      "Test cases run:  500\n",
      "Fails (rate):    83 (16.6%)\n",
      "\n",
      "Example fails:\n",
      "0.5 0.0 0.5 This service is ridiculous.\n",
      "0.2 0.0 0.8 This service is slightly ridiculous.\n",
      "\n",
      "----\n",
      "0.5 0.0 0.5 That pilot was awesome.\n",
      "0.3 0.0 0.7 That pilot was slightly awesome.\n",
      "\n",
      "----\n",
      "0.3 0.0 0.7 This flight is unpleasant.\n",
      "0.1 0.0 0.9 This flight is slightly unpleasant.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "change neutral words with BERT\n",
      "Test cases:      500\n",
      "Fails (rate):    90 (18.0%)\n",
      "\n",
      "Example fails:\n",
      "0.6 0.0 0.4 @SouthwestAir On hold with airline 45 min and counting. Service is terrible!\n",
      "0.4 0.0 0.6 @SouthwestAir On hold per airline 45 min and counting. Service is terrible!\n",
      "\n",
      "----\n",
      "0.7 0.0 0.3 @SouthwestAir no flights to HRL :( is this a limited route?\n",
      "0.5 0.0 0.5 @SouthwestAir no flights via HRL :( is this a limited route?\n",
      "\n",
      "----\n",
      "0.4 0.0 0.6 @AmericanAir @EdPlotts don't bother trying to get anywhere with their customer service team either as take 2+ months and counting to reply\n",
      "0.6 0.0 0.4 @AmericanAir @EdPlotts don't bother trying to get anywhere near their customer service team either as take 2+ months and counting to reply\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "add positive phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    22 (4.4%)\n",
      "\n",
      "Example fails:\n",
      "0.2 0.0 0.8 @SouthwestAir 2/22-MDW 2 SAN flt 1687 attendant Melissa was awesome! Fast, smiling, great. After weather Cancelled Flight day b4, it was welcome\n",
      "0.5 0.0 0.5 @SouthwestAir 2/22-MDW 2 SAN flt 1687 attendant Melissa was awesome! Fast, smiling, great. After weather Cancelled Flight day b4, it was welcome. I value you.\n",
      "0.4 0.0 0.6 @SouthwestAir 2/22-MDW 2 SAN flt 1687 attendant Melissa was awesome! Fast, smiling, great. After weather Cancelled Flight day b4, it was welcome. I like you.\n",
      "\n",
      "----\n",
      "0.4 0.0 0.6 @AmericanAir what name and department does it come under? Thanks\n",
      "0.6 0.0 0.4 @AmericanAir what name and department does it come under? Thanks. I like you.\n",
      "0.5 0.0 0.5 @AmericanAir what name and department does it come under? Thanks. You are wonderful.\n",
      "\n",
      "----\n",
      "0.3 0.0 0.7 @united submitted customer care form Jan 7th. Still no response. A little longer then 7 - 10 business days\n",
      "0.4 0.0 0.6 @united submitted customer care form Jan 7th. Still no response. A little longer then 7 - 10 business days. I like you.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "add negative phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    293 (58.6%)\n",
      "\n",
      "Example fails:\n",
      "0.2 0.0 0.8 @united flight arrives 30 minutes early, but then have we to wait for an hour for our bags.\n",
      "0.2 0.0 0.8 @united flight arrives 30 minutes early, but then have we to wait for an hour for our bags. You are annoying.\n",
      "0.2 0.0 0.8 @united flight arrives 30 minutes early, but then have we to wait for an hour for our bags. You are hard.\n",
      "\n",
      "----\n",
      "0.7 0.0 0.3 @SouthwestAir the sign in screen had major mobile issues, the responsive design wasn't working properly my Nexus 5.\n",
      "0.6 0.0 0.4 @SouthwestAir the sign in screen had major mobile issues, the responsive design wasn't working properly my Nexus 5. I regret you.\n",
      "0.6 0.0 0.4 @SouthwestAir the sign in screen had major mobile issues, the responsive design wasn't working properly my Nexus 5. You are nasty.\n",
      "\n",
      "----\n",
      "0.8 0.0 0.2 @SouthwestAir but to make us tru to find space in other flights.  This customer service is as bad as @SpiritAirlines.\n",
      "0.8 0.0 0.2 @SouthwestAir but to make us tru to find space in other flights.  This customer service is as bad as @SpiritAirlines. You are awful.\n",
      "0.8 0.0 0.2 @SouthwestAir but to make us tru to find space in other flights.  This customer service is as bad as @SpiritAirlines. You are creepy.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Robustness\n",
      "\n",
      "add random urls and handles\n",
      "Test cases:      500\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "punctuation\n",
      "Test cases:      500\n",
      "Fails (rate):    25 (5.0%)\n",
      "\n",
      "Example fails:\n",
      "0.4 0.0 0.6 @united how long does it take to get a response from your customer service about a complaint done through email?\n",
      "0.5 0.0 0.5 @united how long does it take to get a response from your customer service about a complaint done through email\n",
      "\n",
      "----\n",
      "0.5 0.0 0.5 @united I just booked a flight for (2). When I view my reservation it has MI connected to First name. Is this a problem? can it be changed?\n",
      "0.6 0.0 0.4 @united I just booked a flight for (2). When I view my reservation it has MI connected to First name. Is this a problem? can it be changed\n",
      "\n",
      "----\n",
      "0.5 0.0 0.5 @SouthwestAir okay thank you :), also I did get a tweet earlier about 1.5 hrs ago saying I won &amp; should send a DM but then it was deleted?\n",
      "1.0 0.0 0.0 @SouthwestAir okay thank you :), also I did get a tweet earlier about 1.5 hrs ago saying I won &amp; should send a DM but then it was deleted\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "typos\n",
      "Test cases:      500\n",
      "Fails (rate):    24 (4.8%)\n",
      "\n",
      "Example fails:\n",
      "0.3 0.0 0.7 @SouthwestAir no thanks\n",
      "0.5 0.0 0.5 @SouthwestAir no thakns\n",
      "\n",
      "----\n",
      "0.7 0.0 0.3 Really? 9+hours???? @united: @JenniferWalshPR We don't like delays and do all we can to avoid them. We'll have you on your way ASAP\n",
      "0.2 0.0 0.8 Really? 9+hours???? @united: @JenniferWalshPR We don't like delays and do all we can to avoi dthem. We'll have you on your way ASAP\n",
      "\n",
      "----\n",
      "0.5 0.0 0.5 @JetBlue I would fly to Washington  DC to see the actual Constitution  and the Declaration of Independence, in honor of a US Navy friend.\n",
      "0.4 0.0 0.6 @JetBlue I would fly to Wsahington  DC to see the actual Constitution  and the Declaration of Independence, in honor of a US Navy friend.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "2 typos\n",
      "Test cases:      500\n",
      "Fails (rate):    36 (7.2%)\n",
      "\n",
      "Example fails:\n",
      "0.6 0.0 0.4 I appreciate the reply. RT @SouthwestAir: @luxclark We’re so sorry to keep you waiting, Laura. An Agent will be with you shortly...^CB\n",
      "0.2 0.0 0.8 I appreciate the reply. RT @SouthwestAir: @luxclark We’re so sorr yto keep you waiting, Laura. An Agent will be with you shrotly...^CB\n",
      "\n",
      "----\n",
      "0.7 0.0 0.3 @USAirways How dirty does the damn plane have to be to take an hour to get the plane cleaned??? Refund me my miles😡. #wasteoftime #theworst\n",
      "0.3 0.0 0.7 @USAirways How dirty does the damn plane hvae to be to take an hour to get the plane cleaned??? Refudn me my miles😡. #wasteoftime #theworst\n",
      "\n",
      "----\n",
      "0.8 0.0 0.2 @united I have to go back home! I have to use what the company has available. But it's unfair to stay more than 24 h traveling\n",
      "0.4 0.0 0.6 @united I have to go back home! I have to usew hat the company has available. But it's unfair to stay more tha n24 h traveling\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "contractions\n",
      "Test cases:      1000\n",
      "Test cases run:  500\n",
      "Fails (rate):    64 (12.8%)\n",
      "\n",
      "Example fails:\n",
      "0.8 0.0 0.2 @AmericanAir 4th flight rebooked to is NOT Cancelled Flighted! Woo-hoo. Going to make it to @LaGuardiaAir\n",
      "0.4 0.0 0.6 @AmericanAir 4th flight rebooked to isn't Cancelled Flighted! Woo-hoo. Going to make it to @LaGuardiaAir\n",
      "\n",
      "----\n",
      "0.7 0.0 0.3 @AmericanAir as your flight attendants are an extension of your brand - bitchy flight attendants on 5:30 am flights are not appreciated.\n",
      "0.3 0.0 0.7 @AmericanAir as your flight attendants are an extension of your brand - bitchy flight attendants on 5:30 am flights aren't appreciated.\n",
      "\n",
      "----\n",
      "0.6 0.0 0.4 @united #vegan meals can be more creative than noodles, peas, and zukes. Non-vegan yogurt is not acceptable for a vegan. Can you do better?\n",
      "0.2 0.0 0.8 @united #vegan meals can be more creative than noodles, peas, and zukes. Non-vegan yogurt isn't acceptable for a vegan. Can you do better?\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "change names\n",
      "Test cases:      331\n",
      "Fails (rate):    73 (22.1%)\n",
      "\n",
      "Example fails:\n",
      "0.9 0.0 0.1 @united have better customer service at John Wayne airport.\n",
      "0.5 0.0 0.5 @united have better customer service at Joseph Allen.\n",
      "\n",
      "----\n",
      "0.7 0.0 0.3 @jetblue any idea what caused the delay on flight 1316 FLL &gt; Jax ?\n",
      "0.4 0.0 0.6 @jetblue any idea what caused the delay on flight 1316 FLL &gt; Travis ?\n",
      "\n",
      "----\n",
      "0.5 0.0 0.5 @united i emailed the customer care via the website form. After a long wait Rachelle resolved my issue. But I'm still irritated w/ united.\n",
      "0.7 0.0 0.3 @united i emailed the customer care via the website form. After a long wait Christina resolved my issue. But I'm still irritated w/ united.\n",
      "0.7 0.0 0.3 @united i emailed the customer care via the website form. After a long wait Christina resolved my issue. But I'm still irritated w/ united.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "change locations\n",
      "Test cases:      909\n",
      "Test cases run:  500\n",
      "Fails (rate):    101 (20.2%)\n",
      "\n",
      "Example fails:\n",
      "0.6 0.0 0.4 @AmericanAir This is exactly why ill be flying AA from @Dulles_Airport to Dallas! Only airline I trust!\n",
      "0.4 0.0 0.6 @AmericanAir This is exactly why ill be flying AA from @Dulles_Airport to East Orange! Only airline I trust!\n",
      "\n",
      "----\n",
      "0.7 0.0 0.3 @AmericanAir My flight 1389 from Las Vegas to DFW was Cancelled Flightled! I've been on hold forever and I still have not spoken to anyone! Pls Help\n",
      "0.4 0.0 0.6 @AmericanAir My flight 1389 from Cleveland to DFW was Cancelled Flightled! I've been on hold forever and I still have not spoken to anyone! Pls Help\n",
      "\n",
      "----\n",
      "0.6 0.0 0.4 @AmericanAir are flights leaving Dallas right now? In Maui trying to figure out how delayed flight 7 is going to be\n",
      "0.4 0.0 0.6 @AmericanAir are flights leaving Baldwin Park right now? In Maui trying to figure out how delayed flight 7 is going to be\n",
      "0.5 0.0 0.5 @AmericanAir are flights leaving Morgan Hill right now? In Maui trying to figure out how delayed flight 7 is going to be\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "change numbers\n",
      "Test cases:      1000\n",
      "Test cases run:  500\n",
      "Fails (rate):    29 (5.8%)\n",
      "\n",
      "Example fails:\n",
      "0.5 0.0 0.5 @united @NY_NJairports Only at Newark can you land 15 minutes early but lose all that time waiting on tarmac for a gate.\n",
      "0.7 0.0 0.3 @united @NY_NJairports Only at Newark can you land 16 minutes early but lose all that time waiting on tarmac for a gate.\n",
      "0.7 0.0 0.3 @united @NY_NJairports Only at Newark can you land 16 minutes early but lose all that time waiting on tarmac for a gate.\n",
      "\n",
      "----\n",
      "0.5 0.0 0.5 @USAirways 40 minutes to put my TSA number in… 40 mins… and stop holding people hostage with requiring a dividends miles acct. @tsa\n",
      "0.2 0.0 0.8 @USAirways 47 minutes to put my TSA number in… 47 mins… and stop holding people hostage with requiring a dividends miles acct. @tsa\n",
      "0.2 0.0 0.8 @USAirways 45 minutes to put my TSA number in… 45 mins… and stop holding people hostage with requiring a dividends miles acct. @tsa\n",
      "\n",
      "----\n",
      "0.6 0.0 0.4 @AmericanAir POOR EXPERIENCE 2day at ord chkin. 8 emp. w/3 cust. 10 waiting. Asked to speak w/supervisor. Told 20 min. In a mtg!! What?!?!\n",
      "0.4 0.0 0.6 @AmericanAir POOR EXPERIENCE 2day at ord chkin. 8 emp. w/3 cust. 10 waiting. Asked to speak w/supervisor. Told 25 min. In a mtg!! What?!?!\n",
      "0.4 0.0 0.6 @AmericanAir POOR EXPERIENCE 2day at ord chkin. 8 emp. w/3 cust. 10 waiting. Asked to speak w/supervisor. Told 25 min. In a mtg!! What?!?!\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Fairness\n",
      "\n",
      "protected: race\n",
      "Test cases:      600\n",
      "Test cases run:  500\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "protected: sexual\n",
      "Test cases:      600\n",
      "Test cases run:  500\n",
      "Fails (rate):    27 (5.4%)\n",
      "\n",
      "Example fails:\n",
      "0.6 0.0 0.4 Leslie is an asexual athlete.\n",
      "0.5 0.0 0.5 Leslie is a trans athlete.\n",
      "\n",
      "----\n",
      "0.6 0.0 0.4 Leslie is an asexual transsexual.\n",
      "0.5 0.0 0.5 Leslie is a trans transsexual.\n",
      "\n",
      "----\n",
      "0.5 0.0 0.5 Mason is an asexual figure.\n",
      "0.4 0.0 0.6 Mason is a trans figure.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "protected: religion\n",
      "Test cases:      600\n",
      "Test cases run:  500\n",
      "Fails (rate):    385 (77.0%)\n",
      "\n",
      "Example fails:\n",
      "0.4 0.0 0.6 Olivia is a Christian Scientist.\n",
      "0.6 0.0 0.4 Olivia is a Roman Catholic Scientist.\n",
      "\n",
      "----\n",
      "0.4 0.0 0.6 Cody is a Christian conservative.\n",
      "0.6 0.0 0.4 Cody is a Roman Catholic conservative.\n",
      "\n",
      "----\n",
      "0.4 0.0 0.6 Riley is a Christian nun.\n",
      "0.6 0.0 0.4 Riley is a Roman Catholic nun.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "protected: nationality\n",
      "Test cases:      600\n",
      "Test cases run:  500\n",
      "Fails (rate):    385 (77.0%)\n",
      "\n",
      "Example fails:\n",
      "0.6 0.0 0.4 Aiden is a Chinese billionaire.\n",
      "0.2 0.0 0.8 Aiden is a Japanese billionaire.\n",
      "0.3 0.0 0.7 Aiden is a Russian billionaire.\n",
      "\n",
      "----\n",
      "0.7 0.0 0.3 Leslie is a Chinese psychologist.\n",
      "0.3 0.0 0.7 Leslie is a Japanese psychologist.\n",
      "0.4 0.0 0.6 Leslie is a Russian psychologist.\n",
      "\n",
      "----\n",
      "0.6 0.0 0.4 Brooke is a Chinese princess.\n",
      "0.2 0.0 0.8 Brooke is a Japanese princess.\n",
      "0.3 0.0 0.7 Brooke is a Russian princess.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Temporal\n",
      "\n",
      "used to, but now\n",
      "Test cases:      8000\n",
      "Test cases run:  500\n",
      "Fails (rate):    255 (51.0%)\n",
      "\n",
      "Example fails:\n",
      "0.5 0.0 0.5 I used to think this airline was fantastic, even though now I think it is sad.\n",
      "----\n",
      "0.8 0.0 0.2 I value this airline,  I used to hate it.\n",
      "----\n",
      "0.6 0.0 0.4 I admire this airline, but in the past I would despise it.\n",
      "----\n",
      "\n",
      "\n",
      "\"used to\" should reduce\n",
      "Test cases:      4368\n",
      "Test cases run:  500\n",
      "After filtering: 432 (86.4%)\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Negation\n",
      "\n",
      "simple negations: negative\n",
      "Test cases:      6318\n",
      "Test cases run:  500\n",
      "Fails (rate):    357 (71.4%)\n",
      "\n",
      "Example fails:\n",
      "0.2 0.0 0.8 I didn't appreciate this food.\n",
      "----\n",
      "0.3 0.0 0.7 This flight isn't amazing.\n",
      "----\n",
      "0.1 0.0 0.9 I can't say I love this cabin crew.\n",
      "----\n",
      "\n",
      "\n",
      "simple negations: not negative\n",
      "Test cases:      6786\n",
      "Test cases run:  500\n",
      "Fails (rate):    354 (70.8%)\n",
      "\n",
      "Example fails:\n",
      "0.5 0.0 0.5 This plane is not poor.\n",
      "----\n",
      "0.6 0.0 0.4 This wasn't a weird plane.\n",
      "----\n",
      "1.0 0.0 0.0 This is not a boring flight.\n",
      "----\n",
      "\n",
      "\n",
      "simple negations: not neutral is still neutral\n",
      "Test cases:      2496\n",
      "Test cases run:  500\n",
      "Fails (rate):    500 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "0.8 0.0 0.2 The aircraft is not Australian.\n",
      "----\n",
      "0.3 0.0 0.7 That wasn't a commercial seat.\n",
      "----\n",
      "0.4 0.0 0.6 I don't think I see the crew.\n",
      "----\n",
      "\n",
      "\n",
      "simple negations: I thought x was positive, but it was not (should be negative)\n",
      "Test cases:      1992\n",
      "Test cases run:  500\n",
      "Fails (rate):    5 (1.0%)\n",
      "\n",
      "Example fails:\n",
      "0.5 0.0 0.5 I thought I would love this flight, but I didn't.\n",
      "----\n",
      "0.5 0.0 0.5 I thought I would love that aircraft, but I didn't.\n",
      "----\n",
      "0.5 0.0 0.5 I thought I would love that airline, but I didn't.\n",
      "----\n",
      "\n",
      "\n",
      "simple negations: I thought x was negative, but it was not (should be neutral or positive)\n",
      "Test cases:      2124\n",
      "Test cases run:  500\n",
      "Fails (rate):    500 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "0.9 0.0 0.1 I thought the company would be nasty, but it wasn't.\n",
      "----\n",
      "0.8 0.0 0.2 I thought this staff would be frustrating, but it wasn't.\n",
      "----\n",
      "0.9 0.0 0.1 I thought the crew would be horrible, but it was not.\n",
      "----\n",
      "\n",
      "\n",
      "simple negations: but it was not (neutral) should still be neutral\n",
      "Test cases:      804\n",
      "Test cases run:  500\n",
      "Fails (rate):    500 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "0.9 0.0 0.1 I thought the airline would be international, but it was not.\n",
      "----\n",
      "0.8 0.0 0.2 I thought this seat would be Israeli, but it wasn't.\n",
      "----\n",
      "0.8 0.0 0.2 I thought I would find this crew, but I didn't.\n",
      "----\n",
      "\n",
      "\n",
      "Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Test cases:      1000\n",
      "Test cases run:  500\n",
      "Fails (rate):    446 (89.2%)\n",
      "\n",
      "Example fails:\n",
      "0.4 0.0 0.6 I don't think, given the time that I've been flying, that that flight was amazing.\n",
      "----\n",
      "0.1 0.0 0.9 I don't think, given my history with airplanes, that the was an awesome company.\n",
      "----\n",
      "0.1 0.0 0.9 I can't say, given the time that I've been flying, that I welcome the cabin crew.\n",
      "----\n",
      "\n",
      "\n",
      "Hard: Negation of negative with neutral stuff in the middle (should be positive or neutral)\n",
      "Test cases:      1000\n",
      "Test cases run:  500\n",
      "Fails (rate):    259 (51.8%)\n",
      "\n",
      "Example fails:\n",
      "0.9 0.0 0.1 i can't say, given it's a Tuesday, that the is a lousy airline.\n",
      "----\n",
      "0.5 0.0 0.5 I don't think, given all that I've seen over the years, that that cabin crew is horrible.\n",
      "----\n",
      "0.7 0.0 0.3 i wouldn't say, given that I am from Brazil, that this was an average seat.\n",
      "----\n",
      "\n",
      "\n",
      "negation of neutral with neutral in the middle, should still neutral\n",
      "Test cases:      1000\n",
      "Test cases run:  500\n",
      "Fails (rate):    500 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "0.4 0.0 0.6 I don't think, given that I am from Brazil, that that company is Italian.\n",
      "----\n",
      "0.3 0.0 0.7 I don't think, given it's a Tuesday, that we see that seat.\n",
      "----\n",
      "0.1 0.0 0.9 I don't think, given my history with airplanes, that this plane is international.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SRL\n",
      "\n",
      "my opinion is what matters\n",
      "Test cases:      8528\n",
      "Test cases run:  500\n",
      "Fails (rate):    254 (50.8%)\n",
      "\n",
      "Example fails:\n",
      "0.3 0.0 0.7 I had heard you were nice, but I think you are ridiculous.\n",
      "----\n",
      "0.3 0.0 0.7 I think you are creepy, but I had heard you were sweet.\n",
      "----\n",
      "0.4 0.0 0.6 some people admire you, but I abhor you.\n",
      "----\n",
      "\n",
      "\n",
      "Q & A: yes\n",
      "Test cases:      7644\n",
      "Test cases run:  500\n",
      "Fails (rate):    142 (28.4%)\n",
      "\n",
      "Example fails:\n",
      "0.4 0.0 0.6 Do I think that food is frustrating? Yes\n",
      "----\n",
      "0.4 0.0 0.6 Do I think the flight is ridiculous? Yes\n",
      "----\n",
      "0.6 0.0 0.4 Do I think the cabin crew was nice? Yes\n",
      "----\n",
      "\n",
      "\n",
      "Q & A: yes (neutral)\n",
      "Test cases:      1560\n",
      "Test cases run:  500\n",
      "Fails (rate):    500 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "0.5 0.0 0.5 Do I think it is an Italian airline? Yes\n",
      "----\n",
      "0.6 0.0 0.4 Do I think that company was private? Yes\n",
      "----\n",
      "0.4 0.0 0.6 Do I think it is a commercial service? Yes\n",
      "----\n",
      "\n",
      "\n",
      "Q & A: no\n",
      "Test cases:      7644\n",
      "Test cases run:  500\n",
      "Fails (rate):    376 (75.2%)\n",
      "\n",
      "Example fails:\n",
      "0.6 0.0 0.4 Do I think that pilot is lousy? No\n",
      "----\n",
      "0.7 0.0 0.3 Do I think the staff is hard? No\n",
      "----\n",
      "0.7 0.0 0.3 Do I think the airline was ugly? No\n",
      "----\n",
      "\n",
      "\n",
      "Q & A: no (neutral)\n",
      "Test cases:      1560\n",
      "Test cases run:  500\n",
      "Fails (rate):    500 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "0.6 0.0 0.4 Do I think this is an American food? No\n",
      "----\n",
      "0.7 0.0 0.3 Do I think this was a British crew? No\n",
      "----\n",
      "0.6 0.0 0.4 Do I think this is an international food? No\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import checklist\n",
    "from checklist.test_suite import TestSuite\n",
    "suite_path = 'Data/sentiment_suite.pkl'\n",
    "suite = TestSuite.from_file(suite_path)\n",
    "\n",
    "pred_path = 'Data/checklist.pred'\n",
    "suite.run_from_file(pred_path, overwrite=True)\n",
    "suite.summary() # or suite.visual_summary_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-cyprus",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('s', mode='w') as file:\n",
    "    suite.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "logical-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = {'verified':None,'reviewTime':None,'reviewerID':None,'asin':None,\"reviewText\":None,\"summary\":None,\"unixReviewTime\":None,\"sentiment\":None,\"id\":None}\n",
    "\n",
    "with open(\"Data/clean_cases.csv\") as f:\n",
    "    with open(\"Data/clean_cases.json\", 'w') as o:\n",
    "        for line in f:\n",
    "            text, sentiment, *_ = line.split('\\t')\n",
    "            c = cols.copy()\n",
    "            c[\"text\"] = text\n",
    "            c[\"sentiment\"] = sentiment\n",
    "            o.write(str(c))\n",
    "            o.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "experienced-decimal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0ea86566b447598890d777327425d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'gpt_neo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-bf50f9add0f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text-generation'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'EleutherAI/gpt-neo-1.3B'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"EleutherAI has\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Christoffer\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, framework, revision, use_fast, model_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_default_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargeted_task\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m     \u001b[1;31m# Try to infer tokenizer from model or config name (if provided as str)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Christoffer\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py\u001b[0m in \u001b[0;36mget_framework\u001b[1;34m(model, revision)\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mto\u001b[0m \u001b[0minfer\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mframework\u001b[0m \u001b[1;32mfrom\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mIf\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mto\u001b[0m \u001b[0minfer\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mframewrok\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mfrom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mmodel_classes\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdictionary\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mto\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0moptional\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0mframework\u001b[0m \u001b[0mto\u001b[0m \u001b[1;32mclass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mrevision\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0moptional\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Christoffer\\anaconda3\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Christoffer\\anaconda3\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[1;31m# Change some config attributes when loading a pretrained config.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m             \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bert-base-uncased'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfoo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m             \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m             \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m             \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munused_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bert-base-uncased'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfoo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_unused_kwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'gpt_neo'"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "generator = pipeline('text-generation', model='EleutherAI/gpt-neo-1.3B')\n",
    "generator(\"EleutherAI has\", do_sample=True, min_length=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-sleeping",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "parliamentary-channel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size=2):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores\n",
    "\n",
    "model = LSTMTagger(embedding_dim=50, hidden_dim=10, vocab_size=len(vocab))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(10): \n",
    "    for sentence, label in zip(df.reviewText, target):\n",
    "        model.zero_grad()\n",
    "\n",
    "        pred = model(sentence)\n",
    "\n",
    "        loss = loss_function(pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "\n",
    "    print(tag_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "asian-crest",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df = 25)\n",
    "vectorizer.fit(df.reviewText)\n",
    "vocab = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "roman-arbor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7422"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "primary-quebec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        0\n",
       "2        0\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "99995    1\n",
       "99996    0\n",
       "99997    1\n",
       "99998    0\n",
       "99999    0\n",
       "Name: sentiment, Length: 100000, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
